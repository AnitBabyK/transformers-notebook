# transformers-notebook

We will in this repo our resources regarding the transformers library.  
If you want more information, please check our article [Divide Hugging Face Transformers training time by 2 or more with dynamic padding and uniform length batching](https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e?source=friends_link&sk=10a45a0ace94b3255643d81b6475f409).
