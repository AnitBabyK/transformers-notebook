# transformers-notebook

We will in this repo our resources regarding the transformers library.  
If you want more information, please check our article [Divide Hugging Face Transformers training time by 2 or more with dynamic padding and uniform length batching](https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e?source=friends_link&sk=10a45a0ace94b3255643d81b6475f409).

The notebook is available on Google Colab [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CBfRU1zbfu7-ijiOqAAQUA-RJaxfcJoO?usp=sharing)
